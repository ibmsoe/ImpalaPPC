From 3d1056df5c6bbb067c1b1b25249300c27c3083c0 Mon Sep 17 00:00:00 2001
From: Huaxiang Sun <hsun@cloudera.com>
Date: Fri, 8 Jan 2016 17:32:08 -0800
Subject: [PATCH 165/197] HBASE-8329 Limit compaction speed (addendum)
 Reason: New Feature
 Author: Duo Zhang
 Ref: CDH-35507

Change-Id: I510fece5b57471db902a3ef02c81b7a04fcc50f6
---
 .../hadoop/hbase/mob/DefaultMobCompactor.java      |   15 ++++++++++-----
 .../hadoop/hbase/regionserver/HMobStore.java       |   14 ++++++++++----
 2 files changed, 20 insertions(+), 9 deletions(-)

diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/mob/DefaultMobCompactor.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/mob/DefaultMobCompactor.java
index ec0cfe5..dac77a1 100644
--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/mob/DefaultMobCompactor.java
+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/mob/DefaultMobCompactor.java
@@ -39,11 +39,13 @@ import org.apache.hadoop.hbase.regionserver.HStore;
 import org.apache.hadoop.hbase.regionserver.InternalScanner;
 import org.apache.hadoop.hbase.regionserver.MobCompactionStoreScanner;
 import org.apache.hadoop.hbase.regionserver.ScanType;
+import org.apache.hadoop.hbase.regionserver.ScannerContext;
 import org.apache.hadoop.hbase.regionserver.Store;
 import org.apache.hadoop.hbase.regionserver.StoreFile;
 import org.apache.hadoop.hbase.regionserver.StoreFile.Writer;
 import org.apache.hadoop.hbase.regionserver.StoreFileScanner;
 import org.apache.hadoop.hbase.regionserver.compactions.DefaultCompactor;
+import org.apache.hadoop.hbase.regionserver.compactions.CompactionThroughputController;
 import org.apache.hadoop.hbase.util.Bytes;
 
 /**
@@ -71,15 +73,15 @@ public class DefaultMobCompactor extends DefaultCompactor {
   /**
    * Creates a writer for a new file in a temporary directory.
    * @param fd The file details.
-   * @param smallestReadPoint The smallest mvcc readPoint across all the scanners in this region.
+   * @param shouldDropBehind Should the writer drop behind.
    * @return Writer for a new StoreFile in the tmp dir.
    * @throws IOException
    */
   @Override
-  protected Writer createTmpWriter(FileDetails fd, long smallestReadPoint) throws IOException {
+  protected Writer createTmpWriter(FileDetails fd, boolean shouldDropBehind) throws IOException {
     // make this writer with tags always because of possible new cells with tags.
     StoreFile.Writer writer = store.createWriterInTmp(fd.maxKeyCount, this.compactionCompression,
-        true, fd.maxMVCCReadpoint >= smallestReadPoint, true);
+      true, true, true, shouldDropBehind);
     return writer;
   }
 
@@ -142,7 +144,8 @@ public class DefaultMobCompactor extends DefaultCompactor {
    */
   @Override
   protected boolean performCompaction(FileDetails fd, InternalScanner scanner, CellSink writer,
-      long smallestReadPoint, boolean cleanSeqId, boolean major) throws IOException {
+      long smallestReadPoint, boolean cleanSeqId,
+      CompactionThroughputController throughputController, boolean major) throws IOException {
     if (!(scanner instanceof MobCompactionStoreScanner)) {
       throw new IllegalArgumentException(
           "The scanner should be an instance of MobCompactionStoreScanner");
@@ -181,8 +184,10 @@ public class DefaultMobCompactor extends DefaultCompactor {
       }
       delFileWriter = mobStore.createDelFileWriterInTmp(new Date(fd.latestPutTs), fd.maxKeyCount,
           store.getFamily().getCompression(), store.getRegionInfo().getStartKey());
+      ScannerContext scannerContext =
+        ScannerContext.newBuilder().setBatchLimit(compactionKVMax).build();
       do {
-        hasMore = compactionScanner.next(cells, compactionKVMax);
+        hasMore = compactionScanner.next(cells, scannerContext);
         // output to writer:
         for (Cell c : cells) {
           // TODO remove the KeyValueUtil.ensureKeyValue before merging back to trunk.
diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HMobStore.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HMobStore.java
index 6487486..4ef425a 100644
--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HMobStore.java
+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HMobStore.java
@@ -28,6 +28,8 @@ import java.util.NavigableSet;
 import java.util.UUID;
 import java.util.concurrent.ConcurrentHashMap;
 
+import org.apache.commons.logging.Log;
+import org.apache.commons.logging.LogFactory;
 import org.apache.hadoop.classification.InterfaceAudience;
 import org.apache.hadoop.conf.Configuration;
 import org.apache.hadoop.fs.FileSystem;
@@ -58,7 +60,9 @@ import org.apache.hadoop.hbase.mob.MobFileName;
 import org.apache.hadoop.hbase.mob.MobStoreEngine;
 import org.apache.hadoop.hbase.mob.MobUtils;
 import org.apache.hadoop.hbase.regionserver.compactions.CompactionContext;
+import org.apache.hadoop.hbase.regionserver.compactions.CompactionThroughputController;
 import org.apache.hadoop.hbase.util.Bytes;
+import org.apache.hadoop.hbase.util.ChecksumType;
 import org.apache.hadoop.hbase.util.HFileArchiveUtil;
 import org.apache.hadoop.hbase.util.IdLock;
 
@@ -81,6 +85,7 @@ import org.apache.hadoop.hbase.util.IdLock;
 @InterfaceAudience.Private
 public class HMobStore extends HStore {
 
+  private static final Log LOG = LogFactory.getLog(HMobStore.class);
   private MobCacheConfig mobCacheConfig;
   private Path homePath;
   private Path mobFamilyPath;
@@ -248,7 +253,7 @@ public class HMobStore extends HStore {
     final CacheConfig writerCacheConf = mobCacheConfig;
     HFileContext hFileContext = new HFileContextBuilder().withCompression(compression)
         .withIncludesMvcc(true).withIncludesTags(true)
-        .withChecksumType(HFile.DEFAULT_CHECKSUM_TYPE)
+        .withChecksumType(ChecksumType.getDefaultChecksumType())
         .withBytesPerCheckSum(HFile.DEFAULT_BYTES_PER_CHECKSUM)
         .withBlockSize(getFamily().getBlocksize())
         .withHBaseCheckSum(true).withDataBlockEncoding(getFamily().getDataBlockEncoding()).build();
@@ -452,7 +457,8 @@ public class HMobStore extends HStore {
    * The major compaction is marked as retainDeleteMarkers when a sweeping is in progress.
    */
   @Override
-  public List<StoreFile> compact(CompactionContext compaction) throws IOException {
+  public List<StoreFile> compact(CompactionContext compaction,
+      CompactionThroughputController throughputController) throws IOException {
     // If it's major compaction, try to find whether there's a sweeper is running
     // If yes, mark the major compaction as retainDeleteMarkers
     if (compaction.getRequest().isAllFiles()) {
@@ -489,7 +495,7 @@ public class HMobStore extends HStore {
               + tableName + "], forcing the delete markers to be retained");
           compaction.getRequest().forceRetainDeleteMarkers();
         }
-        return super.compact(compaction);
+        return super.compact(compaction, throughputController);
       } finally {
         if (tableLocked && lock != null) {
           try {
@@ -501,7 +507,7 @@ public class HMobStore extends HStore {
       }
     } else {
       // If it's not a major compaction, continue the compaction.
-      return super.compact(compaction);
+      return super.compact(compaction, throughputController);
     }
   }
 
-- 
1.7.0.4

