# basic analytic with default window and no partition/ordering
select count(*) over() from functional.alltypesagg
---- PLAN
01:ANALYTIC
|  functions: count(*)
|
00:SCAN HDFS [functional.alltypesagg]
   partitions=11/11 size=814.73KB
---- DISTRIBUTEDPLAN
01:ANALYTIC
|  functions: count(*)
|
02:EXCHANGE [UNPARTITIONED]
|
00:SCAN HDFS [functional.alltypesagg]
   partitions=11/11 size=814.73KB
====
# basic analytic with default window and partition
select tinyint_col, sum(bigint_col) over(partition by tinyint_col) sum_of_bigints
from functional.alltypesagg
---- PLAN
02:ANALYTIC
|  functions: sum(bigint_col)
|  partition by: tinyint_col
|
01:SORT
|  order by: tinyint_col ASC NULLS FIRST
|
00:SCAN HDFS [functional.alltypesagg]
   partitions=11/11 size=814.73KB
---- DISTRIBUTEDPLAN
04:EXCHANGE [UNPARTITIONED]
|
02:ANALYTIC
|  functions: sum(bigint_col)
|  partition by: tinyint_col
|
01:SORT
|  order by: tinyint_col ASC NULLS FIRST
|
03:EXCHANGE [HASH(tinyint_col)]
|
00:SCAN HDFS [functional.alltypesagg]
   partitions=11/11 size=814.73KB
====
# basic analytic with default window and ordering
select int_col, rank() over(order by int_col) from functional.alltypesagg
---- PLAN
02:ANALYTIC
|  functions: rank()
|  order by: int_col ASC
|  window: RANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW
|
01:SORT
|  order by: int_col ASC
|
00:SCAN HDFS [functional.alltypesagg]
   partitions=11/11 size=814.73KB
---- DISTRIBUTEDPLAN
02:ANALYTIC
|  functions: rank()
|  order by: int_col ASC
|  window: RANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW
|
01:SORT
|  order by: int_col ASC
|
03:EXCHANGE [UNPARTITIONED]
|
00:SCAN HDFS [functional.alltypesagg]
   partitions=11/11 size=814.73KB
====
# analytic rows window, partition and ordering using complex expressions, with limit
select bigint_col, count(double_col)
  over(partition by tinyint_col + 1, double_col / 2 order by 4 - int_col, 4 * smallint_col
  rows between 1 preceding and 1 following)
from functional.alltypesagg
limit 10
---- PLAN
02:ANALYTIC
|  functions: count(double_col)
|  partition by: tinyint_col + 1, double_col / 2
|  order by: 4 - int_col ASC, 4 * smallint_col ASC
|  window: ROWS BETWEEN 1 PRECEDING AND 1 FOLLOWING
|  limit: 10
|
01:SORT
|  order by: tinyint_col + 1 ASC NULLS FIRST, double_col / 2 ASC NULLS FIRST, 4 - int_col ASC, 4 * smallint_col ASC
|
00:SCAN HDFS [functional.alltypesagg]
   partitions=11/11 size=814.73KB
---- DISTRIBUTEDPLAN
04:EXCHANGE [UNPARTITIONED]
|  limit: 10
|
02:ANALYTIC
|  functions: count(double_col)
|  partition by: tinyint_col + 1, double_col / 2
|  order by: 4 - int_col ASC, 4 * smallint_col ASC
|  window: ROWS BETWEEN 1 PRECEDING AND 1 FOLLOWING
|  limit: 10
|
01:SORT
|  order by: tinyint_col + 1 ASC NULLS FIRST, double_col / 2 ASC NULLS FIRST, 4 - int_col ASC, 4 * smallint_col ASC
|
03:EXCHANGE [HASH(tinyint_col + 1,double_col / 2)]
|
00:SCAN HDFS [functional.alltypesagg]
   partitions=11/11 size=814.73KB
====
# test de-duplication of analytic exprs
select
count(bigint_col)
  over(partition by bool_col order by int_col desc rows between 1 preceding and 1 following),
min(double_col)
  over(partition by bool_col order by int_col desc rows between 2 preceding and 2 following),
sum(double_col)
  over(partition by bool_col order by int_col desc rows between 1 preceding and 1 following),
# duplicate analytic expr
count(bigint_col)
  over(partition by bool_col order by int_col desc rows between 1 preceding and 1 following),
min(double_col)
  over(order by int_col desc rows between 1 preceding and 1 following),
# duplicate analytic expr
min(double_col)
  over(partition by bool_col order by int_col desc rows between 2 preceding and 2 following)
from functional.alltypes
limit 10
---- PLAN
05:ANALYTIC
|  functions: min(double_col)
|  order by: int_col DESC
|  window: ROWS BETWEEN 1 PRECEDING AND 1 FOLLOWING
|  limit: 10
|
04:SORT
|  order by: int_col DESC
|
03:ANALYTIC
|  functions: min(double_col)
|  partition by: bool_col
|  order by: int_col DESC
|  window: ROWS BETWEEN 2 PRECEDING AND 2 FOLLOWING
|
02:ANALYTIC
|  functions: count(bigint_col), sum(double_col)
|  partition by: bool_col
|  order by: int_col DESC
|  window: ROWS BETWEEN 1 PRECEDING AND 1 FOLLOWING
|
01:SORT
|  order by: bool_col ASC NULLS FIRST, int_col DESC
|
00:SCAN HDFS [functional.alltypes]
   partitions=24/24 size=478.45KB
---- DISTRIBUTEDPLAN
05:ANALYTIC
|  functions: min(double_col)
|  order by: int_col DESC
|  window: ROWS BETWEEN 1 PRECEDING AND 1 FOLLOWING
|  limit: 10
|
04:SORT
|  order by: int_col DESC
|
07:EXCHANGE [UNPARTITIONED]
|
03:ANALYTIC
|  functions: min(double_col)
|  partition by: bool_col
|  order by: int_col DESC
|  window: ROWS BETWEEN 2 PRECEDING AND 2 FOLLOWING
|
02:ANALYTIC
|  functions: count(bigint_col), sum(double_col)
|  partition by: bool_col
|  order by: int_col DESC
|  window: ROWS BETWEEN 1 PRECEDING AND 1 FOLLOWING
|
01:SORT
|  order by: bool_col ASC NULLS FIRST, int_col DESC
|
06:EXCHANGE [HASH(bool_col)]
|
00:SCAN HDFS [functional.alltypes]
   partitions=24/24 size=478.45KB
====
# analytic on the output of a join with a final order by
select a.tinyint_col, a.int_col, count(a.double_col)
  over(partition by a.tinyint_col order by a.int_col desc rows between 1 preceding and 1 following)
from functional.alltypes a inner join functional.alltypessmall b on a.id = b.id
order by a.tinyint_col, a.int_col
---- PLAN
05:SORT
|  order by: tinyint_col ASC, int_col ASC
|
04:ANALYTIC
|  functions: count(double_col)
|  partition by: a.tinyint_col
|  order by: int_col DESC
|  window: ROWS BETWEEN 1 PRECEDING AND 1 FOLLOWING
|
03:SORT
|  order by: tinyint_col ASC NULLS FIRST, int_col DESC
|
02:HASH JOIN [INNER JOIN]
|  hash predicates: a.id = b.id
|
|--01:SCAN HDFS [functional.alltypessmall b]
|     partitions=4/4 size=6.32KB compact
|
00:SCAN HDFS [functional.alltypes a]
   partitions=24/24 size=478.45KB
---- DISTRIBUTEDPLAN
08:MERGING-EXCHANGE [UNPARTITIONED]
|  order by: tinyint_col ASC, int_col ASC
|
05:SORT
|  order by: tinyint_col ASC, int_col ASC
|
04:ANALYTIC
|  functions: count(double_col)
|  partition by: a.tinyint_col
|  order by: int_col DESC
|  window: ROWS BETWEEN 1 PRECEDING AND 1 FOLLOWING
|
03:SORT
|  order by: tinyint_col ASC NULLS FIRST, int_col DESC
|
07:EXCHANGE [HASH(a.tinyint_col)]
|
02:HASH JOIN [INNER JOIN, BROADCAST]
|  hash predicates: a.id = b.id
|
|--06:EXCHANGE [BROADCAST]
|  |
|  01:SCAN HDFS [functional.alltypessmall b]
|     partitions=4/4 size=6.32KB
|
00:SCAN HDFS [functional.alltypes a]
   partitions=24/24 size=478.45KB
====
# analytics on a grouped aggregation with a final order by
select bool_col,
sum(min(int_col))
  over(partition by min(tinyint_col) order by max(int_col)
  rows between unbounded preceding and 1 following),
max(sum(bigint_col))
  over(partition by min(tinyint_col) order by max(int_col)
  rows between unbounded preceding and 1 following),
min(sum(bigint_col))
  over(partition by min(tinyint_col) order by sum(int_col)
  rows between unbounded preceding and 4 following)
from functional.alltypes
group by 1
order by 1, 2, 3
---- PLAN
06:SORT
|  order by: bool_col ASC, sum(min(int_col)) ASC, max(sum(bigint_col)) ASC
|
05:ANALYTIC
|  functions: min(sum(bigint_col))
|  partition by: min(tinyint_col)
|  order by: sum(int_col) ASC
|  window: ROWS BETWEEN UNBOUNDED PRECEDING AND 4 FOLLOWING
|
04:SORT
|  order by: min(tinyint_col) ASC NULLS FIRST, sum(int_col) ASC
|
03:ANALYTIC
|  functions: sum(min(int_col)), max(sum(bigint_col))
|  partition by: min(tinyint_col)
|  order by: max(int_col) ASC
|  window: ROWS BETWEEN UNBOUNDED PRECEDING AND 1 FOLLOWING
|
02:SORT
|  order by: min(tinyint_col) ASC NULLS FIRST, max(int_col) ASC
|
01:AGGREGATE [FINALIZE]
|  output: min(int_col), min(tinyint_col), max(int_col), sum(bigint_col), sum(int_col)
|  group by: bool_col
|
00:SCAN HDFS [functional.alltypes]
   partitions=24/24 size=478.45KB
---- DISTRIBUTEDPLAN
10:MERGING-EXCHANGE [UNPARTITIONED]
|  order by: bool_col ASC, sum(min(int_col)) ASC, max(sum(bigint_col)) ASC
|
06:SORT
|  order by: bool_col ASC, sum(min(int_col)) ASC, max(sum(bigint_col)) ASC
|
05:ANALYTIC
|  functions: min(sum(bigint_col))
|  partition by: min(tinyint_col)
|  order by: sum(int_col) ASC
|  window: ROWS BETWEEN UNBOUNDED PRECEDING AND 4 FOLLOWING
|
04:SORT
|  order by: min(tinyint_col) ASC NULLS FIRST, sum(int_col) ASC
|
03:ANALYTIC
|  functions: sum(min(int_col)), max(sum(bigint_col))
|  partition by: min(tinyint_col)
|  order by: max(int_col) ASC
|  window: ROWS BETWEEN UNBOUNDED PRECEDING AND 1 FOLLOWING
|
02:SORT
|  order by: min(tinyint_col) ASC NULLS FIRST, max(int_col) ASC
|
09:EXCHANGE [HASH(min(tinyint_col))]
|
08:AGGREGATE [FINALIZE]
|  output: min:merge(int_col), min:merge(tinyint_col), max:merge(int_col), sum:merge(bigint_col), sum:merge(int_col)
|  group by: bool_col
|
07:EXCHANGE [HASH(bool_col)]
|
01:AGGREGATE
|  output: min(int_col), min(tinyint_col), max(int_col), sum(bigint_col), sum(int_col)
|  group by: bool_col
|
00:SCAN HDFS [functional.alltypes]
   partitions=24/24 size=478.45KB
====
# grouping of multiple analytic exprs by compatible window/partition/order
select
count(double_col)
  over(partition by tinyint_col, double_col order by int_col desc
  rows between 1 preceding and 1 following),
max(tinyint_col)
  over(partition by double_col, tinyint_col order by int_col desc
  rows between 1 preceding and 1 following),
# compatible default RANGE window
sum(tinyint_col)
  over(partition by tinyint_col, double_col order by int_col desc),
# compatible RANGE window
sum(smallint_col)
  over(partition by double_col, tinyint_col order by int_col desc
  range between 1 preceding and 1 following),
# different window
min(int_col)
  over(partition by double_col, tinyint_col order by int_col desc
  rows between 2 preceding and 2 following),
# different sort order but same partition
max(int_col)
  over(partition by double_col, tinyint_col order by int_col asc
  rows between 2 preceding and 2 following),
# different partition
min(int_col)
  over(partition by tinyint_col order by int_col desc
  rows between 2 preceding and 2 following)
from functional.alltypesagg
---- PLAN
09:ANALYTIC
|  functions: min(int_col)
|  partition by: tinyint_col
|  order by: int_col DESC
|  window: ROWS BETWEEN 2 PRECEDING AND 2 FOLLOWING
|
08:SORT
|  order by: tinyint_col ASC NULLS FIRST, int_col DESC
|
07:ANALYTIC
|  functions: max(int_col)
|  partition by: double_col, tinyint_col
|  order by: int_col ASC
|  window: ROWS BETWEEN 2 PRECEDING AND 2 FOLLOWING
|
06:SORT
|  order by: double_col ASC NULLS FIRST, tinyint_col ASC NULLS FIRST, int_col ASC
|
05:ANALYTIC
|  functions: min(int_col)
|  partition by: double_col, tinyint_col
|  order by: int_col DESC
|  window: ROWS BETWEEN 2 PRECEDING AND 2 FOLLOWING
|
04:ANALYTIC
|  functions: sum(smallint_col)
|  partition by: double_col, tinyint_col
|  order by: int_col DESC
|  window: RANGE BETWEEN 1 PRECEDING AND 1 FOLLOWING
|
03:ANALYTIC
|  functions: sum(tinyint_col)
|  partition by: tinyint_col, double_col
|  order by: int_col DESC
|  window: RANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW
|
02:ANALYTIC
|  functions: count(double_col), max(tinyint_col)
|  partition by: tinyint_col, double_col
|  order by: int_col DESC
|  window: ROWS BETWEEN 1 PRECEDING AND 1 FOLLOWING
|
01:SORT
|  order by: tinyint_col ASC NULLS FIRST, double_col ASC NULLS FIRST, int_col DESC
|
00:SCAN HDFS [functional.alltypesagg]
   partitions=11/11 size=814.73KB
---- DISTRIBUTEDPLAN
12:EXCHANGE [UNPARTITIONED]
|
09:ANALYTIC
|  functions: min(int_col)
|  partition by: tinyint_col
|  order by: int_col DESC
|  window: ROWS BETWEEN 2 PRECEDING AND 2 FOLLOWING
|
08:SORT
|  order by: tinyint_col ASC NULLS FIRST, int_col DESC
|
11:EXCHANGE [HASH(tinyint_col)]
|
07:ANALYTIC
|  functions: max(int_col)
|  partition by: double_col, tinyint_col
|  order by: int_col ASC
|  window: ROWS BETWEEN 2 PRECEDING AND 2 FOLLOWING
|
06:SORT
|  order by: double_col ASC NULLS FIRST, tinyint_col ASC NULLS FIRST, int_col ASC
|
05:ANALYTIC
|  functions: min(int_col)
|  partition by: double_col, tinyint_col
|  order by: int_col DESC
|  window: ROWS BETWEEN 2 PRECEDING AND 2 FOLLOWING
|
04:ANALYTIC
|  functions: sum(smallint_col)
|  partition by: double_col, tinyint_col
|  order by: int_col DESC
|  window: RANGE BETWEEN 1 PRECEDING AND 1 FOLLOWING
|
03:ANALYTIC
|  functions: sum(tinyint_col)
|  partition by: tinyint_col, double_col
|  order by: int_col DESC
|  window: RANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW
|
02:ANALYTIC
|  functions: count(double_col), max(tinyint_col)
|  partition by: tinyint_col, double_col
|  order by: int_col DESC
|  window: ROWS BETWEEN 1 PRECEDING AND 1 FOLLOWING
|
01:SORT
|  order by: tinyint_col ASC NULLS FIRST, double_col ASC NULLS FIRST, int_col DESC
|
10:EXCHANGE [HASH(tinyint_col,double_col)]
|
00:SCAN HDFS [functional.alltypesagg]
   partitions=11/11 size=814.73KB
====
# grouping of multiple analytic exprs by compatible window/partition/order
# TODO: Unpartitioned analytic exprs should go last. We could even do
# a sort-merge exchange instead of an unpartitioned sort if we're lucky.
# TODO: We can avoid the second sort.
select
count(double_col)
  over(partition by tinyint_col, double_col order by int_col desc
  rows between 1 preceding and 1 following),
# unpartitioned default RANGE window
sum(tinyint_col)
  over(order by int_col desc),
# partition compatible with first analytic expr but no order by
sum(smallint_col)
  over(partition by double_col, tinyint_col),
# incompatible analytic expr
max(smallint_col)
  over(partition by bigint_col order by tinyint_col
  rows between 2 preceding and 2 following)
from functional.alltypesagg
---- PLAN
08:ANALYTIC
|  functions: max(smallint_col)
|  partition by: bigint_col
|  order by: tinyint_col ASC
|  window: ROWS BETWEEN 2 PRECEDING AND 2 FOLLOWING
|
07:SORT
|  order by: bigint_col ASC NULLS FIRST, tinyint_col ASC
|
06:ANALYTIC
|  functions: sum(tinyint_col)
|  order by: int_col DESC
|  window: RANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW
|
05:SORT
|  order by: int_col DESC
|
04:ANALYTIC
|  functions: sum(smallint_col)
|  partition by: double_col, tinyint_col
|
03:SORT
|  order by: double_col ASC NULLS FIRST, tinyint_col ASC NULLS FIRST
|
02:ANALYTIC
|  functions: count(double_col)
|  partition by: tinyint_col, double_col
|  order by: int_col DESC
|  window: ROWS BETWEEN 1 PRECEDING AND 1 FOLLOWING
|
01:SORT
|  order by: tinyint_col ASC NULLS FIRST, double_col ASC NULLS FIRST, int_col DESC
|
00:SCAN HDFS [functional.alltypesagg]
   partitions=11/11 size=814.73KB
---- DISTRIBUTEDPLAN
12:EXCHANGE [UNPARTITIONED]
|
08:ANALYTIC
|  functions: max(smallint_col)
|  partition by: bigint_col
|  order by: tinyint_col ASC
|  window: ROWS BETWEEN 2 PRECEDING AND 2 FOLLOWING
|
07:SORT
|  order by: bigint_col ASC NULLS FIRST, tinyint_col ASC
|
11:EXCHANGE [HASH(bigint_col)]
|
06:ANALYTIC
|  functions: sum(tinyint_col)
|  order by: int_col DESC
|  window: RANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW
|
05:SORT
|  order by: int_col DESC
|
10:EXCHANGE [UNPARTITIONED]
|
04:ANALYTIC
|  functions: sum(smallint_col)
|  partition by: double_col, tinyint_col
|
03:SORT
|  order by: double_col ASC NULLS FIRST, tinyint_col ASC NULLS FIRST
|
02:ANALYTIC
|  functions: count(double_col)
|  partition by: tinyint_col, double_col
|  order by: int_col DESC
|  window: ROWS BETWEEN 1 PRECEDING AND 1 FOLLOWING
|
01:SORT
|  order by: tinyint_col ASC NULLS FIRST, double_col ASC NULLS FIRST, int_col DESC
|
09:EXCHANGE [HASH(tinyint_col,double_col)]
|
00:SCAN HDFS [functional.alltypesagg]
   partitions=11/11 size=814.73KB
====
# basic test for analytics and inline views
select double_col, a, b, a + b, double_col + a from
  (select
   double_col,
   count(int_col) over() a,
   sum(int_col + bigint_col) over(partition by bool_col) b
   from
     (select * from functional.alltypes) v1) v2
order by 2, 3, 4
---- PLAN
04:SORT
|  order by: a ASC, b ASC, a + b ASC
|
03:ANALYTIC
|  functions: sum(int_col + bigint_col)
|  partition by: bool_col
|
02:SORT
|  order by: bool_col ASC NULLS FIRST
|
01:ANALYTIC
|  functions: count(functional.alltypes.int_col)
|
00:SCAN HDFS [functional.alltypes]
   partitions=24/24 size=478.45KB
---- DISTRIBUTEDPLAN
07:MERGING-EXCHANGE [UNPARTITIONED]
|  order by: a ASC, b ASC, a + b ASC
|
04:SORT
|  order by: a ASC, b ASC, a + b ASC
|
03:ANALYTIC
|  functions: sum(int_col + bigint_col)
|  partition by: bool_col
|
02:SORT
|  order by: bool_col ASC NULLS FIRST
|
06:EXCHANGE [HASH(functional.alltypes.bool_col)]
|
01:ANALYTIC
|  functions: count(functional.alltypes.int_col)
|
05:EXCHANGE [UNPARTITIONED]
|
00:SCAN HDFS [functional.alltypes]
   partitions=24/24 size=478.45KB
====
# same as above but using a WITH-clause view
with v2 as
  (select
   double_col,
   count(int_col) over() a,
   sum(int_col + bigint_col) over(partition by bool_col) b
   from
     (select * from functional.alltypes) v1)
select double_col, a, b, a + b, double_col + a from v2
order by 2, 3, 4
---- PLAN
04:SORT
|  order by: a ASC, b ASC, a + b ASC
|
03:ANALYTIC
|  functions: sum(int_col + bigint_col)
|  partition by: bool_col
|
02:SORT
|  order by: bool_col ASC NULLS FIRST
|
01:ANALYTIC
|  functions: count(functional.alltypes.int_col)
|
00:SCAN HDFS [functional.alltypes]
   partitions=24/24 size=478.45KB
---- DISTRIBUTEDPLAN
07:MERGING-EXCHANGE [UNPARTITIONED]
|  order by: a ASC, b ASC, a + b ASC
|
04:SORT
|  order by: a ASC, b ASC, a + b ASC
|
03:ANALYTIC
|  functions: sum(int_col + bigint_col)
|  partition by: bool_col
|
02:SORT
|  order by: bool_col ASC NULLS FIRST
|
06:EXCHANGE [HASH(functional.alltypes.bool_col)]
|
01:ANALYTIC
|  functions: count(functional.alltypes.int_col)
|
05:EXCHANGE [UNPARTITIONED]
|
00:SCAN HDFS [functional.alltypes]
   partitions=24/24 size=478.45KB
====
# test ignoring of non-materialized analytic exprs
select b from
  (select
   count(int_col) over(order by id) a,
   sum(int_col) over(partition by bigint_col) b,
   max(tinyint_col) over() c,
   min(double_col) over(partition by bool_col order by string_col) d,
   count(1) over(partition by bool_col order by string_col
                 rows between unbounded preceding and 1 following) e
   from functional.alltypes) v
where e < 10
---- PLAN
05:SELECT
|  predicates: count(1) < 10
|
04:ANALYTIC
|  functions: count(1)
|  partition by: bool_col
|  order by: string_col ASC
|  window: ROWS BETWEEN UNBOUNDED PRECEDING AND 1 FOLLOWING
|
03:SORT
|  order by: bool_col ASC NULLS FIRST, string_col ASC
|
02:ANALYTIC
|  functions: sum(int_col)
|  partition by: bigint_col
|
01:SORT
|  order by: bigint_col ASC NULLS FIRST
|
00:SCAN HDFS [functional.alltypes]
   partitions=24/24 size=478.45KB
---- DISTRIBUTEDPLAN
08:EXCHANGE [UNPARTITIONED]
|
05:SELECT
|  predicates: count(1) < 10
|
04:ANALYTIC
|  functions: count(1)
|  partition by: bool_col
|  order by: string_col ASC
|  window: ROWS BETWEEN UNBOUNDED PRECEDING AND 1 FOLLOWING
|
03:SORT
|  order by: bool_col ASC NULLS FIRST, string_col ASC
|
07:EXCHANGE [HASH(bool_col)]
|
02:ANALYTIC
|  functions: sum(int_col)
|  partition by: bigint_col
|
01:SORT
|  order by: bigint_col ASC NULLS FIRST
|
06:EXCHANGE [HASH(bigint_col)]
|
00:SCAN HDFS [functional.alltypes]
   partitions=24/24 size=478.45KB
====
# basic test for analytics and unions
select min(id) over (partition by int_col)
  from functional.alltypes
union distinct
select max(id) over (partition by bool_col)
  from functional.alltypessmall
union all
(select sum(bigint_col) over (partition by int_col order by id)
 from functional.alltypestiny)
order by 1 desc nulls first
---- PLAN
12:SORT
|  order by: min(id) OVER(...) DESC NULLS FIRST
|
08:UNION
|
|--07:AGGREGATE [FINALIZE]
|  |  group by: min(id) OVER(...)
|  |
|  00:UNION
|  |
|  |--06:ANALYTIC
|  |  |  functions: max(id)
|  |  |  partition by: bool_col
|  |  |
|  |  05:SORT
|  |  |  order by: bool_col ASC NULLS FIRST
|  |  |
|  |  04:SCAN HDFS [functional.alltypessmall]
|  |     partitions=4/4 size=6.32KB
|  |
|  03:ANALYTIC
|  |  functions: min(id)
|  |  partition by: int_col
|  |
|  02:SORT
|  |  order by: int_col ASC NULLS FIRST
|  |
|  01:SCAN HDFS [functional.alltypes]
|     partitions=24/24 size=478.45KB
|
11:ANALYTIC
|  functions: sum(bigint_col)
|  partition by: int_col
|  order by: id ASC
|  window: RANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW
|
10:SORT
|  order by: int_col ASC NULLS FIRST, id ASC
|
09:SCAN HDFS [functional.alltypestiny]
   partitions=4/4 size=460B
---- DISTRIBUTEDPLAN
18:MERGING-EXCHANGE [UNPARTITIONED]
|  order by: min(id) OVER(...) DESC NULLS FIRST
|
12:SORT
|  order by: min(id) OVER(...) DESC NULLS FIRST
|
08:UNION
|
|--11:ANALYTIC
|  |  functions: sum(bigint_col)
|  |  partition by: int_col
|  |  order by: id ASC
|  |  window: RANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW
|  |
|  10:SORT
|  |  order by: int_col ASC NULLS FIRST, id ASC
|  |
|  13:EXCHANGE [HASH(int_col)]
|  |
|  09:SCAN HDFS [functional.alltypestiny]
|     partitions=4/4 size=460B
|
17:AGGREGATE [FINALIZE]
|  group by: min(id) OVER(...)
|
16:EXCHANGE [HASH(min(id) OVER(...))]
|
07:AGGREGATE
|  group by: min(id) OVER(...)
|
00:UNION
|
|--06:ANALYTIC
|  |  functions: max(id)
|  |  partition by: bool_col
|  |
|  05:SORT
|  |  order by: bool_col ASC NULLS FIRST
|  |
|  15:EXCHANGE [HASH(bool_col)]
|  |
|  04:SCAN HDFS [functional.alltypessmall]
|     partitions=4/4 size=6.32KB
|
03:ANALYTIC
|  functions: min(id)
|  partition by: int_col
|
02:SORT
|  order by: int_col ASC NULLS FIRST
|
14:EXCHANGE [HASH(int_col)]
|
01:SCAN HDFS [functional.alltypes]
   partitions=24/24 size=478.45KB
====
# analytics in an uncorrelated subquery
select id, int_col, bool_col from functional.alltypestiny t1
where int_col in
  (select min(bigint_col) over(partition by bool_col)
   from functional.alltypessmall t2 where t2.id < 10)
---- PLAN
04:HASH JOIN [LEFT SEMI JOIN]
|  hash predicates: int_col = min(bigint_col)
|
|--03:ANALYTIC
|  |  functions: min(bigint_col)
|  |  partition by: bool_col
|  |
|  02:SORT
|  |  order by: bool_col ASC NULLS FIRST
|  |
|  01:SCAN HDFS [functional.alltypessmall t2]
|     partitions=4/4 size=6.32KB
|     predicates: t2.id < 10
|
00:SCAN HDFS [functional.alltypestiny t1]
   partitions=4/4 size=460B
---- DISTRIBUTEDPLAN
08:EXCHANGE [UNPARTITIONED]
|
04:HASH JOIN [LEFT SEMI JOIN, PARTITIONED]
|  hash predicates: int_col = min(bigint_col)
|
|--07:EXCHANGE [HASH(min(bigint_col))]
|  |
|  03:ANALYTIC
|  |  functions: min(bigint_col)
|  |  partition by: bool_col
|  |
|  02:SORT
|  |  order by: bool_col ASC NULLS FIRST
|  |
|  05:EXCHANGE [HASH(bool_col)]
|  |
|  01:SCAN HDFS [functional.alltypessmall t2]
|     partitions=4/4 size=6.32KB
|     predicates: t2.id < 10
|
06:EXCHANGE [HASH(int_col)]
|
00:SCAN HDFS [functional.alltypestiny t1]
   partitions=4/4 size=460B
====
# test conjunct assignment and slot materialization due to conjuncts
# (see IMPALA-1243)
select 1 from
  (select bigint_col,
   min(int_col) over() a,
   max(int_col) over(partition by bool_col) b,
   count(int_col) over(partition by bool_col) c,
   sum(int_col) over(partition by bigint_col order by id
                     rows between unbounded preceding and 1 following) d,
   avg(int_col) over(partition by bigint_col order by id
                     rows between unbounded preceding and 2 following) e
   from functional.alltypes
# assigned in scan
   where int_col between 5 and 10) v
where
# assigned to separate Select node
  v.bigint_col > 10 and
  v.a < 1 and
  v.a < v.bigint_col + 1 and
  v.b < 2 and
  v.b < v.bigint_col + 2 and
  v.c < 3 and
  v.c < v.bigint_col + 3 and
  v.d < 4 and
  v.d < v.bigint_col + 4 and
  v.e < 5 and
  v.e < v.bigint_col + 5 and
  v.a != v.c and
  v.a != v.e and
  v.b != v.c
---- PLAN
07:SELECT
|  predicates: bigint_col > 10, min(int_col) < 1, min(int_col) < bigint_col + 1, max(int_col) < 2, max(int_col) < bigint_col + 2, count(int_col) < 3, count(int_col) < bigint_col + 3, sum(int_col) < 4, sum(int_col) < bigint_col + 4, avg(int_col) < 5, avg(int_col) < bigint_col + 5, min(int_col) != count(int_col), min(int_col) != avg(int_col), max(int_col) != count(int_col)
|
06:ANALYTIC
|  functions: avg(int_col)
|  partition by: bigint_col
|  order by: id ASC
|  window: ROWS BETWEEN UNBOUNDED PRECEDING AND 2 FOLLOWING
|
05:ANALYTIC
|  functions: sum(int_col)
|  partition by: bigint_col
|  order by: id ASC
|  window: ROWS BETWEEN UNBOUNDED PRECEDING AND 1 FOLLOWING
|
04:SORT
|  order by: bigint_col ASC NULLS FIRST, id ASC
|
03:ANALYTIC
|  functions: max(int_col), count(int_col)
|  partition by: bool_col
|
02:SORT
|  order by: bool_col ASC NULLS FIRST
|
01:ANALYTIC
|  functions: min(int_col)
|
00:SCAN HDFS [functional.alltypes]
   partitions=24/24 size=478.45KB
   predicates: int_col >= 5, int_col <= 10
====
# test predicate propagation onto and through analytic nodes
# TODO: allow AnalyticEvalNode to apply a < 20
select 1 from
  (select id, int_col, bigint_col,
   sum(int_col) over(partition by bigint_col order by id
                     rows between unbounded preceding and 1 following) a,
   avg(int_col) over(partition by bigint_col order by id
                     rows between unbounded preceding and 2 following) b
   from functional.alltypes) t1
inner join functional.alltypes t2
on (t1.id = t2.id and t1.a = t2.int_col)
where t2.id < 10 and t2.int_col < 20
---- PLAN
04:HASH JOIN [INNER JOIN]
|  hash predicates: id = t2.id, sum(int_col) = t2.int_col
|
|--03:SCAN HDFS [functional.alltypes t2]
|     partitions=24/24 size=478.45KB compact
|     predicates: t2.id < 10, t2.int_col < 20
|
02:ANALYTIC
|  functions: sum(int_col)
|  partition by: bigint_col
|  order by: id ASC
|  window: ROWS BETWEEN UNBOUNDED PRECEDING AND 1 FOLLOWING
|
01:SORT
|  order by: bigint_col ASC NULLS FIRST, id ASC
|
00:SCAN HDFS [functional.alltypes]
   partitions=24/24 size=478.45KB
====
# test that predicates are correctly propagated in the presence of outer joins
# (i.e., no predicates should be propagated in this query)
select 1 from
  (select id, int_col, bigint_col,
   sum(int_col) over(partition by bigint_col order by id
                     rows between unbounded preceding and 1 following) a,
   avg(int_col) over(partition by bigint_col order by id
                     rows between unbounded preceding and 2 following) b
   from functional.alltypes) t1
left outer join functional.alltypes t2
on (t1.id = t2.id and t1.a = t2.int_col)
where t2.id < 10 and t2.int_col < 20
---- PLAN
04:HASH JOIN [LEFT OUTER JOIN]
|  hash predicates: id = t2.id, sum(int_col) = t2.int_col
|  other predicates: t2.id < 10, t2.int_col < 20
|
|--03:SCAN HDFS [functional.alltypes t2]
|     partitions=24/24 size=478.45KB compact
|     predicates: t2.id < 10, t2.int_col < 20
|
02:ANALYTIC
|  functions: sum(int_col)
|  partition by: bigint_col
|  order by: id ASC
|  window: ROWS BETWEEN UNBOUNDED PRECEDING AND 1 FOLLOWING
|
01:SORT
|  order by: bigint_col ASC NULLS FIRST, id ASC
|
00:SCAN HDFS [functional.alltypes]
   partitions=24/24 size=478.45KB
====
# test canonical function/window/order: row_number() gets a ROWS window
select
row_number() over(partition by tinyint_col order by id)
from functional.alltypesagg
---- PLAN
02:ANALYTIC
|  functions: row_number()
|  partition by: tinyint_col
|  order by: id ASC
|  window: ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW
|
01:SORT
|  order by: tinyint_col ASC NULLS FIRST, id ASC
|
00:SCAN HDFS [functional.alltypesagg]
   partitions=11/11 size=814.73KB
====
# test canonical function/window/order: lead() and lag() have default
# arguments explicitly set
select
lead(int_col) over(partition by tinyint_col order by id),
lag(int_col) over(partition by tinyint_col order by id),
lead(int_col, 4) over(partition by smallint_col order by id),
lag(int_col, 4) over(partition by smallint_col order by id),
lead(int_col, 8, 20) over(partition by int_col order by id),
lag(int_col, 8, 20) over(partition by int_col order by id)
from functional.alltypesagg
---- PLAN
09:ANALYTIC
|  functions: lag(int_col, 8, 20)
|  partition by: int_col
|  order by: id ASC
|  window: ROWS BETWEEN UNBOUNDED PRECEDING AND 8 PRECEDING
|
08:ANALYTIC
|  functions: lead(int_col, 8, 20)
|  partition by: int_col
|  order by: id ASC
|  window: ROWS BETWEEN UNBOUNDED PRECEDING AND 8 FOLLOWING
|
07:SORT
|  order by: int_col ASC NULLS FIRST, id ASC
|
06:ANALYTIC
|  functions: lag(int_col, 4, NULL)
|  partition by: smallint_col
|  order by: id ASC
|  window: ROWS BETWEEN UNBOUNDED PRECEDING AND 4 PRECEDING
|
05:ANALYTIC
|  functions: lead(int_col, 4, NULL)
|  partition by: smallint_col
|  order by: id ASC
|  window: ROWS BETWEEN UNBOUNDED PRECEDING AND 4 FOLLOWING
|
04:SORT
|  order by: smallint_col ASC NULLS FIRST, id ASC
|
03:ANALYTIC
|  functions: lag(int_col, 1, NULL)
|  partition by: tinyint_col
|  order by: id ASC
|  window: ROWS BETWEEN UNBOUNDED PRECEDING AND 1 PRECEDING
|
02:ANALYTIC
|  functions: lead(int_col, 1, NULL)
|  partition by: tinyint_col
|  order by: id ASC
|  window: ROWS BETWEEN UNBOUNDED PRECEDING AND 1 FOLLOWING
|
01:SORT
|  order by: tinyint_col ASC NULLS FIRST, id ASC
|
00:SCAN HDFS [functional.alltypesagg]
   partitions=11/11 size=814.73KB
====
# Test canonical function/window/order: Reverse windows ending in UNBOUNDED FOLLOWING
# and not starting with UNBOUNDED PRECEDING.
select
# windows and sort order should be reversed
sum(int_col) over(partition by tinyint_col order by id desc nulls first, bool_col asc nulls last
                  rows between 2 preceding and unbounded following),
min(int_col) over(partition by tinyint_col order by id asc nulls last
                  range between 4 preceding and unbounded following),
# windows and sort order should remain unchanged
count(bigint_col) over(partition by tinyint_col order by id),
count(bigint_col) over(partition by tinyint_col order by id, int_col
                       rows between 6 preceding and 8 following),
count(bigint_col) over(partition by tinyint_col order by id
                       range between unbounded preceding and 10 following)
from functional.alltypesagg
---- PLAN
09:ANALYTIC
|  functions: count(bigint_col)
|  partition by: tinyint_col
|  order by: id ASC, int_col ASC
|  window: ROWS BETWEEN 6 PRECEDING AND 8 FOLLOWING
|
08:SORT
|  order by: tinyint_col ASC NULLS FIRST, id ASC, int_col ASC
|
07:ANALYTIC
|  functions: count(bigint_col)
|  partition by: tinyint_col
|  order by: id ASC
|  window: RANGE BETWEEN UNBOUNDED PRECEDING AND 10 FOLLOWING
|
06:ANALYTIC
|  functions: count(bigint_col)
|  partition by: tinyint_col
|  order by: id ASC
|  window: RANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW
|
05:SORT
|  order by: tinyint_col ASC NULLS FIRST, id ASC
|
04:ANALYTIC
|  functions: min(int_col)
|  partition by: tinyint_col
|  order by: id DESC
|  window: RANGE BETWEEN UNBOUNDED PRECEDING AND 4 FOLLOWING
|
03:SORT
|  order by: tinyint_col ASC NULLS FIRST, id DESC NULLS FIRST
|
02:ANALYTIC
|  functions: sum(int_col)
|  partition by: tinyint_col
|  order by: id ASC, bool_col DESC
|  window: ROWS BETWEEN UNBOUNDED PRECEDING AND 2 FOLLOWING
|
01:SORT
|  order by: tinyint_col ASC NULLS FIRST, id ASC NULLS LAST, bool_col DESC NULLS FIRST
|
00:SCAN HDFS [functional.alltypesagg]
   partitions=11/11 size=814.73KB
====
# Test canonical function/window/order: Reverse windows ending in UNBOUNDED FOLLOWING
# and not starting with UNBOUNDED PRECEDING, and change first_value() to last_value().
# Set the upper boundary to CURRENT_ROW for first_value() if the lower boundary is
# UNBOUNDED_PRECEDING.
select
# windows, sort order and function should be reversed
first_value(int_col) over(partition by tinyint_col order by id desc nulls first, bool_col asc nulls last
                          rows between 2 preceding and unbounded following),
first_value(int_col) over(partition by tinyint_col order by id asc nulls last
                          range between 4 preceding and unbounded following),
# windows, sort order and function should remain unchanged
first_value(bigint_col) over(partition by tinyint_col order by id),
first_value(bigint_col) over(partition by tinyint_col order by id, int_col
                             rows between 6 preceding and 8 following),
first_value(bigint_col) over(partition by tinyint_col order by id
                             range between unbounded preceding and 10 following)
from functional.alltypesagg
---- PLAN
08:ANALYTIC
|  functions: first_value(bigint_col)
|  partition by: tinyint_col
|  order by: id ASC, int_col ASC
|  window: ROWS BETWEEN 6 PRECEDING AND 8 FOLLOWING
|
07:SORT
|  order by: tinyint_col ASC NULLS FIRST, id ASC, int_col ASC
|
06:ANALYTIC
|  functions: first_value(bigint_col)
|  partition by: tinyint_col
|  order by: id ASC
|  window: RANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW
|
05:SORT
|  order by: tinyint_col ASC NULLS FIRST, id ASC
|
04:ANALYTIC
|  functions: last_value(int_col)
|  partition by: tinyint_col
|  order by: id DESC
|  window: RANGE BETWEEN UNBOUNDED PRECEDING AND 4 FOLLOWING
|
03:SORT
|  order by: tinyint_col ASC NULLS FIRST, id DESC NULLS FIRST
|
02:ANALYTIC
|  functions: last_value(int_col)
|  partition by: tinyint_col
|  order by: id ASC, bool_col DESC
|  window: ROWS BETWEEN UNBOUNDED PRECEDING AND 2 FOLLOWING
|
01:SORT
|  order by: tinyint_col ASC NULLS FIRST, id ASC NULLS LAST, bool_col DESC NULLS FIRST
|
00:SCAN HDFS [functional.alltypesagg]
   partitions=11/11 size=814.73KB
====
# Test canonical function/window/order: Reverse windows ending in UNBOUNDED FOLLOWING
# and not starting with UNBOUNDED PRECEDING, and change last_value() to first_value()
select
# windows, sort order and function should be reversed
last_value(int_col) over(partition by tinyint_col order by id desc nulls first, bool_col asc nulls last
                          rows between 2 preceding and unbounded following),
last_value(int_col) over(partition by tinyint_col order by id asc nulls last
                          range between 4 preceding and unbounded following),
# windows, sort order and function should remain unchanged
last_value(bigint_col) over(partition by tinyint_col order by id),
last_value(bigint_col) over(partition by tinyint_col order by id, int_col
                       rows between 6 preceding and 8 following),
last_value(bigint_col) over(partition by tinyint_col order by id
                            range between unbounded preceding and 10 following)
from functional.alltypesagg
---- PLAN
09:ANALYTIC
|  functions: last_value(bigint_col)
|  partition by: tinyint_col
|  order by: id ASC, int_col ASC
|  window: ROWS BETWEEN 6 PRECEDING AND 8 FOLLOWING
|
08:SORT
|  order by: tinyint_col ASC NULLS FIRST, id ASC, int_col ASC
|
07:ANALYTIC
|  functions: last_value(bigint_col)
|  partition by: tinyint_col
|  order by: id ASC
|  window: RANGE BETWEEN UNBOUNDED PRECEDING AND 10 FOLLOWING
|
06:ANALYTIC
|  functions: last_value(bigint_col)
|  partition by: tinyint_col
|  order by: id ASC
|  window: RANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW
|
05:SORT
|  order by: tinyint_col ASC NULLS FIRST, id ASC
|
04:ANALYTIC
|  functions: first_value(int_col)
|  partition by: tinyint_col
|  order by: id DESC
|  window: RANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW
|
03:SORT
|  order by: tinyint_col ASC NULLS FIRST, id DESC NULLS FIRST
|
02:ANALYTIC
|  functions: first_value(int_col)
|  partition by: tinyint_col
|  order by: id ASC, bool_col DESC
|  window: ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW
|
01:SORT
|  order by: tinyint_col ASC NULLS FIRST, id ASC NULLS LAST, bool_col DESC NULLS FIRST
|
00:SCAN HDFS [functional.alltypesagg]
   partitions=11/11 size=814.73KB
====
# IMPALA-1229
select DENSE_RANK() OVER (ORDER BY t1.day ASC)
FROM functional.alltypesagg t1
WHERE EXISTS (SELECT t1.year AS int_col_1 FROM functional.alltypesagg t1)
---- PLAN
04:ANALYTIC
|  functions: dense_rank()
|  order by: day ASC
|  window: RANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW
|
03:SORT
|  order by: day ASC
|
02:CROSS JOIN [BROADCAST]
|
|--01:SCAN HDFS [functional.alltypesagg t1]
|     partitions=11/11 size=814.73KB compact
|     limit: 1
|
00:SCAN HDFS [functional.alltypesagg t1]
   partitions=11/11 size=814.73KB
====
